{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import mean,col,split, col, regexp_extract, when, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import QuantileDiscretizer\n",
    "\n",
    "# create sparksession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Spark ML example on titanic data\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://96e24061328f:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Spark ML example on titanic data</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8fe6ceb6d8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = spark.read.json('data_titanic.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: double (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: long (nullable = true)\n",
      " |-- cabin: string (nullable = true)\n",
      " |-- embarked: string (nullable = true)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- homeDest: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- parch: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- sibsp: long (nullable = true)\n",
      " |-- survived: long (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1309"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-------+--------+-------+--------------------+--------------------+-----+------+------+-----+--------+--------+\n",
      "| age|boat|body|  cabin|embarked|   fare|            homeDest|                name|parch|pclass|   sex|sibsp|survived|  ticket|\n",
      "+----+----+----+-------+--------+-------+--------------------+--------------------+-----+------+------+-----+--------+--------+\n",
      "| 2.0|    |null|C22 C26|       S| 151.55|Montreal, PQ / Ch...|Allison, Miss. He...|    2|     1|female|    1|       0|  113781|\n",
      "|30.0|    | 135|C22 C26|       S| 151.55|Montreal, PQ / Ch...|Allison, Mr. Huds...|    2|     1|  male|    1|       0|  113781|\n",
      "|25.0|    |null|C22 C26|       S| 151.55|Montreal, PQ / Ch...|Allison, Mrs. Hud...|    2|     1|female|    1|       0|  113781|\n",
      "|39.0|    |null|    A36|       S|    0.0|         Belfast, NI|Andrews, Mr. Thom...|    0|     1|  male|    0|       0|  112050|\n",
      "|71.0|    |  22|       |       C|49.5042| Montevideo, Uruguay|Artagaveytia, Mr....|    0|     1|  male|    0|       0|PC 17609|\n",
      "+----+----+----+-------+--------+-------+--------------------+--------------------+-----+------+------+-----+--------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------------+-----------------+-----+--------+------------------+-------------------+--------------------+------------------+------------------+------+------------------+------------------+------------------+\n",
      "|summary|               age|             boat|             body|cabin|embarked|              fare|           homeDest|                name|             parch|            pclass|   sex|             sibsp|          survived|            ticket|\n",
      "+-------+------------------+-----------------+-----------------+-----+--------+------------------+-------------------+--------------------+------------------+------------------+------+------------------+------------------+------------------+\n",
      "|  count|              1309|             1309|              121| 1309|    1309|              1309|               1309|                1309|              1309|              1309|  1309|              1309|              1309|              1309|\n",
      "|   mean| 29.50318311688312|9.404522613065327|160.8099173553719| null|    null| 33.29143384262795|               null|                null|0.3850267379679144| 2.294881588999236|  null|0.4988540870893812|0.3819709702062643| 249039.1368861024|\n",
      "| stddev|12.905246301411271| 4.35741698360494|97.69692199600308| null|    null|51.739086057579506|               null|                null|0.8655602753495147|0.8378360189701272|  null| 1.041658390596102|0.4860551708664828|442685.31767656445|\n",
      "|    min|            0.1667|                 |                1|     |        |               0.0|                   | Abbing, Mr. Anthony|                 0|                 1|female|                 0|                 0|            110152|\n",
      "|    max|              80.0|                D|              328|    T|       S|          512.3292|Zurich, Switzerland|van Melkebeke, Mr...|                 9|                 3|  male|                 8|                 1|         WE/P 5735|\n",
      "+-------+------------------+-----------------+-----------------+-----+--------+------------------+-------------------+--------------------+------------------+------------------+------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Survived|count|\n",
      "+--------+-----+\n",
      "|       0|  809|\n",
      "|       1|  500|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gropuBy_output = titanic_df.groupBy(\"Survived\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|   Sex|Survived|count|\n",
      "+------+--------+-----+\n",
      "|  male|       0|  682|\n",
      "|female|       1|  339|\n",
      "|female|       0|  127|\n",
      "|  male|       1|  161|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Sex\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+-----+\n",
      "|Pclass|Survived|count|\n",
      "+------+--------+-----+\n",
      "|     3|       0|  528|\n",
      "|     1|       0|  123|\n",
      "|     1|       1|  200|\n",
      "|     2|       0|  158|\n",
      "|     2|       1|  119|\n",
      "|     3|       1|  181|\n",
      "+------+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Pclass\",\"Survived\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it can be seen that the Pclass1 people were given priority to pclass3 people, even though\n",
    "We can clearly see that Passenegers Of Pclass 1 were given a very high priority while rescue. Even though the the number of Passengers in Pclass 3 were a lot higher, still the number of survival from them is very low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function use to print feature with null values and null count \n",
    "def null_value_count(df):\n",
    "  null_columns_counts = []\n",
    "  numRows = df.count()\n",
    "  for k in df.columns:\n",
    "    nullRows = df.where(col(k).isNull()).count()\n",
    "    if(nullRows > 0):\n",
    "      temp = k,nullRows\n",
    "      null_columns_counts.append(temp)\n",
    "  return(null_columns_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_columns_count_list = null_value_count(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------+\n",
      "|Column_With_Null_Value|Null_Values_Count|\n",
      "+----------------------+-----------------+\n",
      "|                  body|             1188|\n",
      "+----------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(null_columns_count_list, ['Column_With_Null_Value', 'Null_Values_Count']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.50318311688312\n"
     ]
    }
   ],
   "source": [
    "mean_age = titanic_df.select(mean('Age')).collect()[0][0]\n",
    "print(mean_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                Name|\n",
      "+--------------------+\n",
      "|Allison, Miss. He...|\n",
      "|Allison, Mr. Huds...|\n",
      "|Allison, Mrs. Hud...|\n",
      "|Andrews, Mr. Thom...|\n",
      "|Artagaveytia, Mr....|\n",
      "|Astor, Col. John ...|\n",
      "| Baumann, Mr. John D|\n",
      "|Baxter, Mr. Quigg...|\n",
      "|Beattie, Mr. Thomson|\n",
      "| Birnbaum, Mr. Jakob|\n",
      "|Blackwell, Mr. St...|\n",
      "|Borebank, Mr. Joh...|\n",
      "|Brady, Mr. John B...|\n",
      "|  Brandeis, Mr. Emil|\n",
      "|Brewe, Dr. Arthur...|\n",
      "|Butt, Major. Arch...|\n",
      "|Cairns, Mr. Alexa...|\n",
      "|Carlsson, Mr. Fra...|\n",
      "|Carrau, Mr. Franc...|\n",
      "|Carrau, Mr. Jose ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Name\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To replace these NaN values, we can assign them the mean age of the dataset.But the problem is, there were many people with many different ages. We just cant assign a 4 year kid with the mean age that is 29 years.\n",
    "we can check the Name feature. Looking upon the feature, we can see that the names have a salutation like Mr or Mrs. Thus we can assign the mean values of Mr and Mrs to the respective groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Initial\",regexp_extract(col(\"Name\"),\"([A-Za-z]+)\\.\",1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Regex \"\"[A-Za-z]+).\" we extract the initials from the Name. It looks for strings which lie between A-Z or a-z and followed by a .(dot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+-----------+--------+--------+--------------------+--------------------+-----+------+------+-----+--------+--------+-------+\n",
      "| age|boat|body|      cabin|embarked|    fare|            homeDest|                name|parch|pclass|   sex|sibsp|survived|  ticket|Initial|\n",
      "+----+----+----+-----------+--------+--------+--------------------+--------------------+-----+------+------+-----+--------+--------+-------+\n",
      "| 2.0|    |null|    C22 C26|       S|  151.55|Montreal, PQ / Ch...|Allison, Miss. He...|    2|     1|female|    1|       0|  113781|   Miss|\n",
      "|30.0|    | 135|    C22 C26|       S|  151.55|Montreal, PQ / Ch...|Allison, Mr. Huds...|    2|     1|  male|    1|       0|  113781|     Mr|\n",
      "|25.0|    |null|    C22 C26|       S|  151.55|Montreal, PQ / Ch...|Allison, Mrs. Hud...|    2|     1|female|    1|       0|  113781|    Mrs|\n",
      "|39.0|    |null|        A36|       S|     0.0|         Belfast, NI|Andrews, Mr. Thom...|    0|     1|  male|    0|       0|  112050|     Mr|\n",
      "|71.0|    |  22|           |       C| 49.5042| Montevideo, Uruguay|Artagaveytia, Mr....|    0|     1|  male|    0|       0|PC 17609|     Mr|\n",
      "|47.0|    | 124|    C62 C64|       C| 227.525|        New York, NY|Astor, Col. John ...|    0|     1|  male|    1|       0|PC 17757|    Col|\n",
      "|28.0|    |null|           |       S|  25.925|        New York, NY| Baumann, Mr. John D|    0|     1|  male|    0|       0|PC 17318|     Mr|\n",
      "|24.0|    |null|    B58 B60|       C|247.5208|        Montreal, PQ|Baxter, Mr. Quigg...|    1|     1|  male|    0|       0|PC 17558|     Mr|\n",
      "|36.0|   A|null|         C6|       C| 75.2417|        Winnipeg, MN|Beattie, Mr. Thomson|    0|     1|  male|    0|       0|   13050|     Mr|\n",
      "|25.0|    | 148|           |       C|    26.0|   San Francisco, CA| Birnbaum, Mr. Jakob|    0|     1|  male|    0|       0|   13905|     Mr|\n",
      "|45.0|    |null|          T|       S|    35.5|         Trenton, NJ|Blackwell, Mr. St...|    0|     1|  male|    0|       0|  113784|     Mr|\n",
      "|42.0|    |null|        D22|       S|   26.55|London / Winnipeg...|Borebank, Mr. Joh...|    0|     1|  male|    0|       0|  110489|     Mr|\n",
      "|41.0|    |null|        A21|       S|    30.5|         Pomeroy, WA|Brady, Mr. John B...|    0|     1|  male|    0|       0|  113054|     Mr|\n",
      "|48.0|    | 208|        B10|       C| 50.4958|           Omaha, NE|  Brandeis, Mr. Emil|    0|     1|  male|    0|       0|PC 17591|     Mr|\n",
      "|28.0|    |null|           |       C|    39.6|    Philadelphia, PA|Brewe, Dr. Arthur...|    0|     1|  male|    0|       0|  112379|     Dr|\n",
      "|45.0|    |null|        B38|       S|   26.55|      Washington, DC|Butt, Major. Arch...|    0|     1|  male|    0|       0|  113050|  Major|\n",
      "|28.0|    |null|           |       S|    31.0|                    |Cairns, Mr. Alexa...|    0|     1|  male|    0|       0|  113798|     Mr|\n",
      "|33.0|    |null|B51 B53 B55|       S|     5.0|        New York, NY|Carlsson, Mr. Fra...|    0|     1|  male|    0|       0|     695|     Mr|\n",
      "|28.0|    |null|           |       S|    47.1| Montevideo, Uruguay|Carrau, Mr. Franc...|    0|     1|  male|    0|       0|  113059|     Mr|\n",
      "|17.0|    |null|           |       S|    47.1| Montevideo, Uruguay|Carrau, Mr. Jose ...|    0|     1|  male|    0|       0|  113059|     Mr|\n",
      "+----+----+----+-----------+--------+--------+--------------------+--------------------+-----+------+------+-----+--------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "| Initial|\n",
      "+--------+\n",
      "|    Dona|\n",
      "|     Don|\n",
      "|    Miss|\n",
      "|Countess|\n",
      "|     Col|\n",
      "|     Rev|\n",
      "|    Lady|\n",
      "|  Master|\n",
      "|    Capt|\n",
      "|     Mme|\n",
      "|      Mr|\n",
      "|      Dr|\n",
      "|     Mrs|\n",
      "|     Sir|\n",
      "|Jonkheer|\n",
      "|    Mlle|\n",
      "|   Major|\n",
      "|      Ms|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some misspelled Initials like Mlle or Mme that stand for Miss. I will replace them with Miss and same thing for other values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.replace(['Mlle','Mme', 'Ms', 'Dr','Major','Lady','Countess','Jonkheer','Col','Rev','Capt','Sir','Don'],\n",
    "               ['Miss','Miss','Miss','Mr','Mr',  'Mrs',  'Mrs',  'Other',  'Other','Other','Mr','Mr','Mr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|   Dona|\n",
      "|   Miss|\n",
      "|  Other|\n",
      "| Master|\n",
      "|     Mr|\n",
      "|    Mrs|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Initial\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets check the average age by Initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Initial='Dona', avg(Age)=39.0),\n",
       " Row(Initial='Miss', avg(Age)=23.021069433962264),\n",
       " Row(Initial='Other', avg(Age)=44.92307692307692),\n",
       " Row(Initial='Master', avg(Age)=8.435791803278688),\n",
       " Row(Initial='Mr', avg(Age)=31.50064935064935),\n",
       " Row(Initial='Mrs', avg(Age)=35.80904522613066)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.groupby('Initial').avg('Age').collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's impute missing values in age feature based on average age of Initials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Miss\") & (titanic_df[\"Age\"].isNull()), 22).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Other\") & (titanic_df[\"Age\"].isNull()), 46).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Master\") & (titanic_df[\"Age\"].isNull()), 5).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mr\") & (titanic_df[\"Age\"].isNull()), 33).otherwise(titanic_df[\"Age\"]))\n",
    "titanic_df = titanic_df.withColumn(\"Age\",when((titanic_df[\"Initial\"] == \"Mrs\") & (titanic_df[\"Age\"].isNull()), 36).otherwise(titanic_df[\"Age\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Initial|\n",
      "+-------+\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "|     Mr|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.filter(titanic_df.Age==46).select(\"Initial\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| Age|\n",
      "+----+\n",
      "| 2.0|\n",
      "|30.0|\n",
      "|25.0|\n",
      "|39.0|\n",
      "|71.0|\n",
      "|47.0|\n",
      "|28.0|\n",
      "|24.0|\n",
      "|36.0|\n",
      "|25.0|\n",
      "|45.0|\n",
      "|42.0|\n",
      "|41.0|\n",
      "|48.0|\n",
      "|28.0|\n",
      "|45.0|\n",
      "|28.0|\n",
      "|33.0|\n",
      "|28.0|\n",
      "|17.0|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.select(\"Age\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embarked feature has only two missining values. Let's check values within Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Embarked|count|\n",
      "+--------+-----+\n",
      "|       Q|  123|\n",
      "|       C|  270|\n",
      "|       S|  914|\n",
      "|        |    2|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Embarked\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority Passengers boarded from \"S\". We can impute with \"S\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.na.fill({\"Embarked\" : 'S'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can drop Cabin features as it has lots of null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"Cabin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: double (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: long (nullable = true)\n",
      " |-- embarked: string (nullable = false)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- homeDest: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- parch: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- sibsp: long (nullable = true)\n",
      " |-- survived: long (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- Initial: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a new feature called \"Family_size\" and \"Alone\" and analyse it. This feature is the summation of Parch(parents/children) and SibSp(siblings/spouses). It gives us a combined data so that we can check if survival rate have anything to do with family size of the passengers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Family_Size\",col('SibSp')+col('Parch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+\n",
      "|Family_Size|count|\n",
      "+-----------+-----+\n",
      "|          0|  790|\n",
      "|          7|    8|\n",
      "|          6|   16|\n",
      "|          5|   25|\n",
      "|          1|  235|\n",
      "|         10|   11|\n",
      "|          3|   43|\n",
      "|          2|  159|\n",
      "|          4|   22|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.groupBy(\"Family_Size\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn('Alone',lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.withColumn(\"Alone\",when(titanic_df[\"Family_Size\"] == 0, 1).otherwise(titanic_df[\"Alone\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age',\n",
       " 'boat',\n",
       " 'body',\n",
       " 'embarked',\n",
       " 'fare',\n",
       " 'homeDest',\n",
       " 'name',\n",
       " 'parch',\n",
       " 'pclass',\n",
       " 'sex',\n",
       " 'sibsp',\n",
       " 'survived',\n",
       " 'ticket',\n",
       " 'Initial',\n",
       " 'Family_Size',\n",
       " 'Alone']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets convert Sex, Embarked & Initial columns from string to number using StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_index\").fit(titanic_df) for column in [\"sex\",\"embarked\",\"Initial\"]]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "titanic_df = pipeline.fit(titanic_df).transform(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+----+--------+--------+--------------------+--------------------+-----+------+------+-----+--------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "| Age|boat|body|embarked|    fare|            homeDest|                name|parch|pclass|   sex|sibsp|survived|  ticket|Initial|Family_Size|Alone|sex_index|embarked_index|Initial_index|\n",
      "+----+----+----+--------+--------+--------------------+--------------------+-----+------+------+-----+--------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "| 2.0|    |null|       S|  151.55|Montreal, PQ / Ch...|Allison, Miss. He...|    2|     1|female|    1|       0|  113781|   Miss|          3|    0|      1.0|           0.0|          1.0|\n",
      "|30.0|    | 135|       S|  151.55|Montreal, PQ / Ch...|Allison, Mr. Huds...|    2|     1|  male|    1|       0|  113781|     Mr|          3|    0|      0.0|           0.0|          0.0|\n",
      "|25.0|    |null|       S|  151.55|Montreal, PQ / Ch...|Allison, Mrs. Hud...|    2|     1|female|    1|       0|  113781|    Mrs|          3|    0|      1.0|           0.0|          2.0|\n",
      "|39.0|    |null|       S|     0.0|         Belfast, NI|Andrews, Mr. Thom...|    0|     1|  male|    0|       0|  112050|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|71.0|    |  22|       C| 49.5042| Montevideo, Uruguay|Artagaveytia, Mr....|    0|     1|  male|    0|       0|PC 17609|     Mr|          0|    1|      0.0|           1.0|          0.0|\n",
      "|47.0|    | 124|       C| 227.525|        New York, NY|Astor, Col. John ...|    0|     1|  male|    1|       0|PC 17757|  Other|          1|    0|      0.0|           1.0|          4.0|\n",
      "|28.0|    |null|       S|  25.925|        New York, NY| Baumann, Mr. John D|    0|     1|  male|    0|       0|PC 17318|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|24.0|    |null|       C|247.5208|        Montreal, PQ|Baxter, Mr. Quigg...|    1|     1|  male|    0|       0|PC 17558|     Mr|          1|    0|      0.0|           1.0|          0.0|\n",
      "|36.0|   A|null|       C| 75.2417|        Winnipeg, MN|Beattie, Mr. Thomson|    0|     1|  male|    0|       0|   13050|     Mr|          0|    1|      0.0|           1.0|          0.0|\n",
      "|25.0|    | 148|       C|    26.0|   San Francisco, CA| Birnbaum, Mr. Jakob|    0|     1|  male|    0|       0|   13905|     Mr|          0|    1|      0.0|           1.0|          0.0|\n",
      "|45.0|    |null|       S|    35.5|         Trenton, NJ|Blackwell, Mr. St...|    0|     1|  male|    0|       0|  113784|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|42.0|    |null|       S|   26.55|London / Winnipeg...|Borebank, Mr. Joh...|    0|     1|  male|    0|       0|  110489|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|41.0|    |null|       S|    30.5|         Pomeroy, WA|Brady, Mr. John B...|    0|     1|  male|    0|       0|  113054|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|48.0|    | 208|       C| 50.4958|           Omaha, NE|  Brandeis, Mr. Emil|    0|     1|  male|    0|       0|PC 17591|     Mr|          0|    1|      0.0|           1.0|          0.0|\n",
      "|28.0|    |null|       C|    39.6|    Philadelphia, PA|Brewe, Dr. Arthur...|    0|     1|  male|    0|       0|  112379|     Mr|          0|    1|      0.0|           1.0|          0.0|\n",
      "|45.0|    |null|       S|   26.55|      Washington, DC|Butt, Major. Arch...|    0|     1|  male|    0|       0|  113050|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|28.0|    |null|       S|    31.0|                    |Cairns, Mr. Alexa...|    0|     1|  male|    0|       0|  113798|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|33.0|    |null|       S|     5.0|        New York, NY|Carlsson, Mr. Fra...|    0|     1|  male|    0|       0|     695|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|28.0|    |null|       S|    47.1| Montevideo, Uruguay|Carrau, Mr. Franc...|    0|     1|  male|    0|       0|  113059|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "|17.0|    |null|       S|    47.1| Montevideo, Uruguay|Carrau, Mr. Jose ...|    0|     1|  male|    0|       0|  113059|     Mr|          0|    1|      0.0|           0.0|          0.0|\n",
      "+----+----+----+--------+--------+--------------------+--------------------+-----+------+------+-----+--------+--------+-------+-----------+-----+---------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Age: double (nullable = true)\n",
      " |-- boat: string (nullable = true)\n",
      " |-- body: long (nullable = true)\n",
      " |-- embarked: string (nullable = false)\n",
      " |-- fare: double (nullable = true)\n",
      " |-- homeDest: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- parch: long (nullable = true)\n",
      " |-- pclass: long (nullable = true)\n",
      " |-- sex: string (nullable = true)\n",
      " |-- sibsp: long (nullable = true)\n",
      " |-- survived: long (nullable = true)\n",
      " |-- ticket: string (nullable = true)\n",
      " |-- Initial: string (nullable = true)\n",
      " |-- Family_Size: long (nullable = true)\n",
      " |-- Alone: integer (nullable = false)\n",
      " |-- sex_index: double (nullable = false)\n",
      " |-- embarked_index: double (nullable = false)\n",
      " |-- Initial_index: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop Columns not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_df = titanic_df.drop(\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\",\"Embarked\",\"Sex\",\"Initial\", \"Boat\", \"homeDest\", \"body\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+------+-----+--------+-----------+-----+---------+--------------+-------------+\n",
      "| Age|    fare|parch|pclass|sibsp|survived|Family_Size|Alone|sex_index|embarked_index|Initial_index|\n",
      "+----+--------+-----+------+-----+--------+-----------+-----+---------+--------------+-------------+\n",
      "| 2.0|  151.55|    2|     1|    1|       0|          3|    0|      1.0|           0.0|          1.0|\n",
      "|30.0|  151.55|    2|     1|    1|       0|          3|    0|      0.0|           0.0|          0.0|\n",
      "|25.0|  151.55|    2|     1|    1|       0|          3|    0|      1.0|           0.0|          2.0|\n",
      "|39.0|     0.0|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|71.0| 49.5042|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|\n",
      "|47.0| 227.525|    0|     1|    1|       0|          1|    0|      0.0|           1.0|          4.0|\n",
      "|28.0|  25.925|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|24.0|247.5208|    1|     1|    0|       0|          1|    0|      0.0|           1.0|          0.0|\n",
      "|36.0| 75.2417|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|\n",
      "|25.0|    26.0|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|\n",
      "|45.0|    35.5|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|42.0|   26.55|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|41.0|    30.5|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|48.0| 50.4958|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|\n",
      "|28.0|    39.6|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|\n",
      "|45.0|   26.55|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|28.0|    31.0|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|33.0|     5.0|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|28.0|    47.1|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "|17.0|    47.1|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|\n",
      "+----+--------+-----+------+-----+--------+-----------+-----+---------+--------------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titanic_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put all features into vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = VectorAssembler(inputCols=titanic_df.columns[1:],outputCol=\"features\")\n",
    "feature_vector= feature.transform(titanic_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+--------+-----+------+-----+--------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "| Age|    fare|parch|pclass|sibsp|survived|Family_Size|Alone|sex_index|embarked_index|Initial_index|            features|\n",
      "+----+--------+-----+------+-----+--------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "| 2.0|  151.55|    2|     1|    1|       0|          3|    0|      1.0|           0.0|          1.0|[151.55,2.0,1.0,1...|\n",
      "|30.0|  151.55|    2|     1|    1|       0|          3|    0|      0.0|           0.0|          0.0|(10,[0,1,2,3,5],[...|\n",
      "|25.0|  151.55|    2|     1|    1|       0|          3|    0|      1.0|           0.0|          2.0|[151.55,2.0,1.0,1...|\n",
      "|39.0|     0.0|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[2,6],[1.0,1.0])|\n",
      "|71.0| 49.5042|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|(10,[0,2,6,8],[49...|\n",
      "|47.0| 227.525|    0|     1|    1|       0|          1|    0|      0.0|           1.0|          4.0|[227.525,0.0,1.0,...|\n",
      "|28.0|  25.925|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[25.9...|\n",
      "|24.0|247.5208|    1|     1|    0|       0|          1|    0|      0.0|           1.0|          0.0|(10,[0,1,2,5,8],[...|\n",
      "|36.0| 75.2417|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|(10,[0,2,6,8],[75...|\n",
      "|25.0|    26.0|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|(10,[0,2,6,8],[26...|\n",
      "|45.0|    35.5|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[35.5...|\n",
      "|42.0|   26.55|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[26.5...|\n",
      "|41.0|    30.5|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[30.5...|\n",
      "|48.0| 50.4958|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|(10,[0,2,6,8],[50...|\n",
      "|28.0|    39.6|    0|     1|    0|       0|          0|    1|      0.0|           1.0|          0.0|(10,[0,2,6,8],[39...|\n",
      "|45.0|   26.55|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[26.5...|\n",
      "|28.0|    31.0|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[31.0...|\n",
      "|33.0|     5.0|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[5.0,...|\n",
      "|28.0|    47.1|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[47.1...|\n",
      "|17.0|    47.1|    0|     1|    0|       0|          0|    1|      0.0|           0.0|          0.0|(10,[0,2,6],[47.1...|\n",
      "+----+--------+-----+------+-----+--------+-----------+-----+---------+--------------+-------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_vector.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the data is all set, let's split it into training and test. I'll be using 80% of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = feature_vector.randomSplit([0.8, 0.2],seed = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling\n",
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of few Classification Algorithms from Spark ML\n",
    "LogisticRegression\n",
    "\n",
    "DecisionTreeClassifier\n",
    "\n",
    "RandomForestClassifier\n",
    "\n",
    "Gradient-boosted tree classifier\n",
    "\n",
    "NaiveBayes\n",
    "\n",
    "Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression\n",
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       1|[14.5,1.0,2.0,1.0...|\n",
      "|       1.0|       1|[29.0,2.0,2.0,0.0...|\n",
      "|       1.0|       1|[27.75,2.0,2.0,1....|\n",
      "|       1.0|       1|[151.55,2.0,1.0,1...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       1.0|       1|[12.2875,1.0,3.0,...|\n",
      "|       1.0|       1|[31.3875,2.0,3.0,...|\n",
      "|       1.0|       1|[11.1333,1.0,3.0,...|\n",
      "|       1.0|       1|[13.4167,1.0,3.0,...|\n",
      "|       0.0|       0|[29.125,1.0,3.0,4...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[21.075,1.0,3.0,3...|\n",
      "|       0.0|       0|[31.3875,2.0,3.0,...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[14.5,1.0,3.0,1.0...|\n",
      "|       1.0|       1|[11.2417,0.0,3.0,...|\n",
      "|       0.0|       0|(10,[0,2,6],[65.0...|\n",
      "|       0.0|       0|[14.4542,0.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "lr = LogisticRegression(labelCol=\"survived\", featuresCol=\"features\")\n",
    "#Training algo\n",
    "lrModel = lr.fit(trainingData)\n",
    "lr_prediction = lrModel.transform(testData)\n",
    "lr_prediction.select(\"prediction\", \"survived\", \"features\").show()\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"survived\", predictionCol=\"prediction\", metricName=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating accuracy of LogisticRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegression is = 1\n",
      "Test Error of LogisticRegression = 0 \n"
     ]
    }
   ],
   "source": [
    "lr_accuracy = evaluator.evaluate(lr_prediction)\n",
    "print(\"Accuracy of LogisticRegression is = %g\"% (lr_accuracy))\n",
    "print(\"Test Error of LogisticRegression = %g \" % (1.0 - lr_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       1|[14.5,1.0,2.0,1.0...|\n",
      "|       1.0|       1|[29.0,2.0,2.0,0.0...|\n",
      "|       1.0|       1|[27.75,2.0,2.0,1....|\n",
      "|       1.0|       1|[151.55,2.0,1.0,1...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       1.0|       1|[12.2875,1.0,3.0,...|\n",
      "|       1.0|       1|[31.3875,2.0,3.0,...|\n",
      "|       1.0|       1|[11.1333,1.0,3.0,...|\n",
      "|       1.0|       1|[13.4167,1.0,3.0,...|\n",
      "|       0.0|       0|[29.125,1.0,3.0,4...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[21.075,1.0,3.0,3...|\n",
      "|       0.0|       0|[31.3875,2.0,3.0,...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[14.5,1.0,3.0,1.0...|\n",
      "|       1.0|       1|[11.2417,0.0,3.0,...|\n",
      "|       0.0|       0|(10,[0,2,6],[65.0...|\n",
      "|       0.0|       0|[14.4542,0.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(labelCol=\"survived\", featuresCol=\"features\")\n",
    "dt_model = dt.fit(trainingData)\n",
    "dt_prediction = dt_model.transform(testData)\n",
    "dt_prediction.select(\"prediction\", \"survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating accuracy of DecisionTreeClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of DecisionTreeClassifier is = 1\n",
      "Test Error of DecisionTreeClassifier = 0 \n"
     ]
    }
   ],
   "source": [
    "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
    "print(\"Accuracy of DecisionTreeClassifier is = %g\"% (dt_accuracy))\n",
    "print(\"Test Error of DecisionTreeClassifier = %g \" % (1.0 - dt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RandomForestClassifier\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       1|[14.5,1.0,2.0,1.0...|\n",
      "|       1.0|       1|[29.0,2.0,2.0,0.0...|\n",
      "|       1.0|       1|[27.75,2.0,2.0,1....|\n",
      "|       1.0|       1|[151.55,2.0,1.0,1...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       1.0|       1|[12.2875,1.0,3.0,...|\n",
      "|       1.0|       1|[31.3875,2.0,3.0,...|\n",
      "|       1.0|       1|[11.1333,1.0,3.0,...|\n",
      "|       1.0|       1|[13.4167,1.0,3.0,...|\n",
      "|       0.0|       0|[29.125,1.0,3.0,4...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[21.075,1.0,3.0,3...|\n",
      "|       0.0|       0|[31.3875,2.0,3.0,...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[14.5,1.0,3.0,1.0...|\n",
      "|       1.0|       1|[11.2417,0.0,3.0,...|\n",
      "|       0.0|       0|(10,[0,2,6],[65.0...|\n",
      "|       0.0|       0|[14.4542,0.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "rf = DecisionTreeClassifier(labelCol=\"survived\", featuresCol=\"features\")\n",
    "rf_model = rf.fit(trainingData)\n",
    "rf_prediction = rf_model.transform(testData)\n",
    "rf_prediction.select(\"prediction\", \"survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating accuracy of RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForestClassifier is = 1\n",
      "Test Error of RandomForestClassifier  = 0 \n"
     ]
    }
   ],
   "source": [
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"Accuracy of RandomForestClassifier is = %g\"% (rf_accuracy))\n",
    "print(\"Test Error of RandomForestClassifier  = %g \" % (1.0 - rf_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient-boosted tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       1|[14.5,1.0,2.0,1.0...|\n",
      "|       1.0|       1|[29.0,2.0,2.0,0.0...|\n",
      "|       1.0|       1|[27.75,2.0,2.0,1....|\n",
      "|       1.0|       1|[151.55,2.0,1.0,1...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       1.0|       1|[12.2875,1.0,3.0,...|\n",
      "|       1.0|       1|[31.3875,2.0,3.0,...|\n",
      "|       1.0|       1|[11.1333,1.0,3.0,...|\n",
      "|       1.0|       1|[13.4167,1.0,3.0,...|\n",
      "|       0.0|       0|[29.125,1.0,3.0,4...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[21.075,1.0,3.0,3...|\n",
      "|       0.0|       0|[31.3875,2.0,3.0,...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[14.5,1.0,3.0,1.0...|\n",
      "|       1.0|       1|[11.2417,0.0,3.0,...|\n",
      "|       0.0|       0|(10,[0,2,6],[65.0...|\n",
      "|       0.0|       0|[14.4542,0.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import GBTClassifier\n",
    "gbt = GBTClassifier(labelCol=\"survived\", featuresCol=\"features\",maxIter=10)\n",
    "gbt_model = gbt.fit(trainingData)\n",
    "gbt_prediction = gbt_model.transform(testData)\n",
    "gbt_prediction.select(\"prediction\", \"survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate accuracy of Gradient-boosted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gradient-boosted tree classifie is = 1\n",
      "Test Error of Gradient-boosted tree classifie 0\n"
     ]
    }
   ],
   "source": [
    "gbt_accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Accuracy of Gradient-boosted tree classifie is = %g\"% (gbt_accuracy))\n",
    "print(\"Test Error of Gradient-boosted tree classifie %g\"% (1.0 - gbt_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NaiveBayes\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       1|[14.5,1.0,2.0,1.0...|\n",
      "|       1.0|       1|[29.0,2.0,2.0,0.0...|\n",
      "|       1.0|       1|[27.75,2.0,2.0,1....|\n",
      "|       1.0|       1|[151.55,2.0,1.0,1...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       1.0|       1|[12.2875,1.0,3.0,...|\n",
      "|       0.0|       1|[31.3875,2.0,3.0,...|\n",
      "|       1.0|       1|[11.1333,1.0,3.0,...|\n",
      "|       1.0|       1|[13.4167,1.0,3.0,...|\n",
      "|       0.0|       0|[29.125,1.0,3.0,4...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[21.075,1.0,3.0,3...|\n",
      "|       0.0|       0|[31.3875,2.0,3.0,...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[14.5,1.0,3.0,1.0...|\n",
      "|       1.0|       1|[11.2417,0.0,3.0,...|\n",
      "|       1.0|       0|(10,[0,2,6],[65.0...|\n",
      "|       0.0|       0|[14.4542,0.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import NaiveBayes\n",
    "nb = NaiveBayes(labelCol=\"survived\", featuresCol=\"features\")\n",
    "nb_model = nb.fit(trainingData)\n",
    "nb_prediction = nb_model.transform(testData)\n",
    "nb_prediction.select(\"prediction\", \"survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating accuracy of NaiveBayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes is  = 0.938776\n",
      "Test Error of NaiveBayes  = 0.0612245 \n"
     ]
    }
   ],
   "source": [
    "nb_accuracy = evaluator.evaluate(nb_prediction)\n",
    "print(\"Accuracy of NaiveBayes is  = %g\"% (nb_accuracy))\n",
    "print(\"Test Error of NaiveBayes  = %g \" % (1.0 - nb_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machine\n",
    "-----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+--------------------+\n",
      "|prediction|survived|            features|\n",
      "+----------+--------+--------------------+\n",
      "|       1.0|       1|[14.5,1.0,2.0,1.0...|\n",
      "|       1.0|       1|[29.0,2.0,2.0,0.0...|\n",
      "|       1.0|       1|[27.75,2.0,2.0,1....|\n",
      "|       1.0|       1|[151.55,2.0,1.0,1...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       1.0|       1|[12.2875,1.0,3.0,...|\n",
      "|       1.0|       1|[31.3875,2.0,3.0,...|\n",
      "|       1.0|       1|[11.1333,1.0,3.0,...|\n",
      "|       1.0|       1|[13.4167,1.0,3.0,...|\n",
      "|       0.0|       0|[29.125,1.0,3.0,4...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[21.075,1.0,3.0,3...|\n",
      "|       0.0|       0|[31.3875,2.0,3.0,...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[46.9,2.0,3.0,5.0...|\n",
      "|       0.0|       0|[31.275,2.0,3.0,4...|\n",
      "|       0.0|       0|[14.5,1.0,3.0,1.0...|\n",
      "|       1.0|       1|[11.2417,0.0,3.0,...|\n",
      "|       0.0|       0|(10,[0,2,6],[65.0...|\n",
      "|       0.0|       0|[14.4542,0.0,3.0,...|\n",
      "+----------+--------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "svm = LinearSVC(labelCol=\"survived\", featuresCol=\"features\")\n",
    "svm_model = svm.fit(trainingData)\n",
    "svm_prediction = svm_model.transform(testData)\n",
    "svm_prediction.select(\"prediction\", \"survived\", \"features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the accuracy of Support Vector Machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Support Vector Machine is = 1\n",
      "Test Error of Support Vector Machine = 0 \n"
     ]
    }
   ],
   "source": [
    "svm_accuracy = evaluator.evaluate(svm_prediction)\n",
    "print(\"Accuracy of Support Vector Machine is = %g\"% (svm_accuracy))\n",
    "print(\"Test Error of Support Vector Machine = %g \" % (1.0 - svm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
